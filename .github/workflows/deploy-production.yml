name: Deploy (Production)
run-name: Production Release ${{ github.ref_name }}

concurrency:
  group: deploy
  cancel-in-progress: false

on:
  push:
    tags:
      - 'v*.*.*'
  workflow_dispatch:

permissions:
  id-token: write
  contents: read
  packages: write

jobs:
  resolve_tag:
    name: Resolve Tag
    runs-on: ubuntu-latest
    outputs:
      tag: ${{ steps.out.outputs.tag }}
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Resolve Tag
        id: out
        run: |
          if [ "${{ github.event_name }}" = "workflow_dispatch" ]; then
            TAG=$(git tag --list 'v[0-9]*.[0-9]*.[0-9]*' --sort=-v:refname | head -n 1)
            [ -n "$TAG" ] || (echo "No version tags found" && exit 1)
          else
            TAG='${{ github.ref_name }}'
          fi
          
          echo "tag=$TAG" >> "$GITHUB_OUTPUT"

      - name: Ensure tag is on default branch
        run: |
          set -e
          git fetch --force --tags origin "${{ github.event.repository.default_branch }}"

          TAG_SHA="$(git rev-list -n 1 "${{ steps.out.outputs.tag }}")"

          git merge-base --is-ancestor \
            "$TAG_SHA" \
            "origin/${{ github.event.repository.default_branch }}" \
            || (echo "Error: Tag ${{ steps.out.outputs.tag }} ($TAG_SHA) is not on origin/${{ github.event.repository.default_branch }}!" && exit 1)

  backend:
    name: Deploy Backend
    runs-on: ubuntu-latest
    needs: resolve_tag

    defaults:
      run:
        working-directory: backend/api

    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          ref: ${{ needs.resolve_tag.outputs.tag }}

      - name: Set up JDK 17
        uses: actions/setup-java@v4
        with:
          distribution: temurin
          java-version: 17
          cache: gradle

      - name: Build JAR
        run: ./gradlew clean bootJar

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Login to GHCR
        uses: docker/login-action@v3
        with:
          registry: ghcr.io
          username: ${{ github.actor }}
          password: ${{ secrets.GITHUB_TOKEN }}

      - name: Build & Push Image
        run: |
          IMAGE=ghcr.io/${{ github.repository_owner }}/episode-api
          TAG='${{ needs.resolve_tag.outputs.tag }}'

          docker buildx build \
            --cache-from type=gha \
            --cache-to type=gha,mode=max \
            --platform linux/arm64 \
            -t $IMAGE:$TAG \
            -t $IMAGE:latest \
            --push .

      - name: Setup SSH
        id: setup_ssh
        run: |
          mkdir -p ~/.ssh
          echo "${{ secrets.EC2_SSH_KEY }}" > ~/.ssh/id_rsa
          chmod 600 ~/.ssh/id_rsa
          ssh-keyscan -H ${{ secrets.EC2_HOST }} >> ~/.ssh/known_hosts

      - name: Backup infra files
        run: |
          ssh ${{ secrets.EC2_USER }}@${{ secrets.EC2_HOST }} << 'EOF'
            set -e
            cd ~/app

            [ -f docker-compose.yml ] && cp docker-compose.yml .docker-compose.prev.yml || echo "No docker-compose to backup"
            [ -f Caddyfile ] && cp Caddyfile .Caddyfile.prev || echo "No Caddyfile to backup"
          EOF

      - name: Sync infra files to server
        working-directory: .
        run: |
          rsync -avz --delete \
            --exclude='.env' \
            --exclude='.Caddyfile.prev' \
            --exclude='.docker-compose.prev.yml' \
            infra/prod/ \
            ${{ secrets.EC2_USER }}@${{ secrets.EC2_HOST }}:/home/${{ secrets.EC2_USER }}/app/

      - name: Deploy
        id: deploy
        run: |
          TAG='${{ needs.resolve_tag.outputs.tag }}'

          ssh ${{ secrets.EC2_USER }}@${{ secrets.EC2_HOST }} "TAG=$TAG bash -s" <<'EOF'
            set -e
            cd ~/app
          
            CURRENT_IMAGE=$(docker inspect episode-api \
            --format '{{.Config.Image}}' 2>/dev/null || true)
          
            if [ -n "$CURRENT_IMAGE" ]; then
              CURRENT_TAG=${CURRENT_IMAGE##*:}
              echo "$CURRENT_TAG" > .prev_tag
              echo "Saved previous tag: $CURRENT_TAG"
            else
              echo "No running container found"
              rm -f .prev_tag || true
            fi
          
            echo "Deploying new tag: $TAG"
            export IMAGE_TAG="$TAG"
          
            docker compose pull
            docker compose up -d
          
            for i in $(seq 1 20); do
              docker compose exec -T caddy caddy version >/dev/null 2>&1 && break
              sleep 1
            done
          
            docker compose exec -T caddy caddy validate --config /etc/caddy/Caddyfile
            docker compose exec -T caddy caddy reload --config /etc/caddy/Caddyfile
          EOF

      - name: Health check
        id: health_check
        run: |
          set -e
          URL="https://api.episode.io.kr/actuator/health/liveness"

          echo "Checking health:"
          for i in $(seq 1 30); do
            resp="$(curl -sS --max-time 5 -w "\n%{http_code}" "$URL" || true)"
            body="$(echo "$resp" | head -n 1)"
            code="$(echo "$resp" | tail -n 1)"

            echo "try=$i http=$code body=$body"

            if [ "$code" = "200" ] && echo "$body" | grep -q '"status":"UP"'; then
              echo "Health is UP"
              exit 0
            fi

            sleep 5
          done

          echo "Health check failed"
          exit 1

      - name: Rollback on failure
        if: failure() && steps.setup_ssh.outcome == 'success'
        run: |
          echo "Health check failed. Rolling back..."
          
          ssh ${{ secrets.EC2_USER }}@${{ secrets.EC2_HOST }} << 'EOF'
          set -e
          cd ~/app

          if [ ! -f .prev_tag ]; then
             echo "No previous tag found. Nothing to rollback."
             exit 0
          fi

          PREV_TAG=$(cat .prev_tag)
          echo "Rolling back to $PREV_TAG"

          [ -f .docker-compose.prev.yml ] && mv .docker-compose.prev.yml docker-compose.yml || true
          [ -f .Caddyfile.prev ] && mv .Caddyfile.prev Caddyfile || true

          export IMAGE_TAG=$PREV_TAG

          docker compose pull
          docker compose up -d
          docker compose exec -T caddy caddy reload --config /etc/caddy/Caddyfile || true

          echo "Rollback completed."
          EOF

      - name: Cleanup Temporary Files & Images
        if: always() && steps.setup_ssh.outcome == 'success'
        run: |
          ssh ${{ secrets.EC2_USER }}@${{ secrets.EC2_HOST }} << 'EOF'
            cd ~/app
            rm -f .prev_tag .docker-compose.prev.yml .Caddyfile.prev
            docker image prune -a -f
          EOF

  frontend_build:
    name: Build Frontend
    runs-on: ubuntu-latest
    needs: resolve_tag

    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          ref: ${{ needs.resolve_tag.outputs.tag }}

      - name: Install pnpm
        uses: pnpm/action-setup@v4
        with:
          version: 10

      - name: Set up Node.js
        uses: actions/setup-node@v4
        with:
          node-version: "24"
          cache: "pnpm"
          cache-dependency-path: ./frontend/pnpm-lock.yaml

      - name: Inject ENV
        working-directory: ./frontend
        run: |
          cat > .env.production << 'EOF'
          ${{ secrets.FRONTEND_ENV_PRODUCTION }}
          EOF

      - name: Install Dependencies
        working-directory: ./frontend
        run: pnpm install --frozen-lockfile

      - name: Build
        working-directory: ./frontend
        run: pnpm build

      - name: Upload build output
        uses: actions/upload-artifact@v4
        with:
          name: frontend-dist
          path: frontend/dist
          if-no-files-found: error

  frontend_deploy:
    name: Deploy Frontend
    runs-on: ubuntu-latest
    needs: [ resolve_tag, backend, frontend_build ]
    if: needs.backend.result == 'success' && needs.frontend_build.result == 'success'

    steps:
      - name: Download build output
        uses: actions/download-artifact@v4
        with:
          name: frontend-dist
          path: dist

      - name: Configure AWS credentials (OIDC)
        uses: aws-actions/configure-aws-credentials@v4
        with:
          role-to-assume: ${{ vars.AWS_DEPLOY_ROLE_ARN }}
          aws-region: ${{ vars.AWS_REGION }}

      - name: Upload to S3
        run: |
          aws s3 sync ./dist s3://${{ vars.PROD_S3_BUCKET }}/ --delete

      - name: Invalidate CloudFront
        run: |
          aws cloudfront create-invalidation \
            --distribution-id ${{ vars.CF_DISTRIBUTION_ID }} \
            --paths "/*"

  yjs_runner_deploy:
    name: Deploy Yjs Runner
    runs-on: ubuntu-latest
    needs: resolve_tag
    permissions:
      contents: read
    defaults:
      run:
        working-directory: backend/yjs-runner
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          ref: ${{ needs.resolve_tag.outputs.tag }}

      - name: Set up QEMU
        uses: docker/setup-qemu-action@v3
        with:
          platforms: arm64

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Setup SSH
        run: |
          mkdir -p ~/.ssh
          echo "${{ secrets.EC2_SSH_KEY }}" > ~/.ssh/id_rsa
          chmod 600 ~/.ssh/id_rsa
          ssh-keyscan -H ${{ secrets.EC2_HOST }} >> ~/.ssh/known_hosts
          ssh -o StrictHostKeyChecking=yes \
            ${{ secrets.EC2_USER }}@${{ secrets.EC2_HOST }} \
            "ssh-keyscan -H ${{ secrets.YJS_HOST }}" >> ~/.ssh/known_hosts

      - name: Install pv & zstd
        run: |
          sudo apt-get update -y
          sudo apt-get install -y pv zstd

      - name: Build & Deploy
        run: |
          set -euo pipefail
          IMAGE=ghcr.io/${{ github.repository_owner }}/episode-yjs-runner
          TAG='${{ needs.resolve_tag.outputs.tag }}'

          docker buildx build \
            --cache-from type=gha,scope=yjs-runner \
            --cache-to type=gha,mode=max,scope=yjs-runner \
            --platform linux/arm64 \
            -t "$IMAGE:$TAG" \
            -t "$IMAGE:latest" \
            --load .

          docker save "$IMAGE:$TAG" | pv -f -ptebar | zstd -T0 -9 | \
            ssh -o StrictHostKeyChecking=yes \
              -o ProxyJump=${{ secrets.EC2_USER }}@${{ secrets.EC2_HOST }} \
              ${{ secrets.YJS_USER }}@${{ secrets.YJS_HOST }} \
              "zstd -d -c | docker load"

          ssh -o StrictHostKeyChecking=yes \
            -o ProxyJump=${{ secrets.EC2_USER }}@${{ secrets.EC2_HOST }} \
            ${{ secrets.YJS_USER }}@${{ secrets.YJS_HOST }} "IMAGE=$IMAGE TAG=$TAG bash -s" <<'EOF'
              set -e
              cd ~/app

              [ -f ~/app/.env ] || (echo "~/app/.env not found" && exit 1)

              docker rm -f episode-yjs-runner || true

              docker run -d \
                --name episode-yjs-runner \
                --env-file ~/app/.env \
                --restart unless-stopped \
                --log-opt max-size=10m \
                --log-opt max-file=3 \
                "$IMAGE:$TAG"

              docker image prune -a -f
          EOF
